{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: audience effect\n",
    "In which we determine whether intended audience (using @-reply as \"audience\") affects Catalan usage in control data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweet_data = pd.read_csv('../../data/tweets/extra_user_tweets/Jan-01-17_Oct-31-17_user_tweets.tsv', sep='\\t', index_col=False)\n",
    "# fillna\n",
    "all_tweet_data.fillna('', inplace=True)\n",
    "print(all_tweet_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag at-replies\n",
    "import re\n",
    "at_matcher = re.compile('@\\w+')\n",
    "all_tweet_data.loc[:, 'reply'] = all_tweet_data.apply(lambda r: int(len(at_matcher.findall(r.loc['text'])) > 0 and r.loc['retweeted']==0), axis=1)\n",
    "# and hashtag counts\n",
    "all_tweet_data.loc[:, 'hashtag_count'] = all_tweet_data.loc[:, 'hashtags'].apply(lambda x: len(x.split(',')) if x != '' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for difference in reply vs. non-reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.812205\n",
      "1    0.187795\n",
      "Name: reply, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_tweet_data.loc[:, 'reply'].value_counts() / all_tweet_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 18% of tweets are replies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter for retweets\n",
    "tweet_data_original = all_tweet_data[all_tweet_data.loc[:, 'retweeted'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.510152\n",
      "1    0.489848\n",
      "Name: reply, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# count replies\n",
    "print(tweet_data_original.loc[:, 'reply'].value_counts() / tweet_data_original.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better ratio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "$H_{0}$: Tweeters who use @-replies are just as likely to use Catalan in @-reply as in non-reply (controlling for hashtag usage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1267\n",
      "1     386\n",
      "Name: reply, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweet_data_original_with_ref = tweet_data_original[tweet_data_original.loc[:, 'contains_ref_hashtag']==1]\n",
    "print(tweet_data_original_with_ref.loc[:, 'reply'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small sample size...but we push ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 relevant users\n",
      "128 relevant tweets\n"
     ]
    }
   ],
   "source": [
    "relevant_users = tweet_data_original_with_ref.groupby('user').apply(lambda x: (x.loc[:, 'reply'].min()==0 and\n",
    "                                                                               x.loc[:, 'reply'].max()==1))\n",
    "relevant_users = relevant_users[relevant_users].index.tolist()\n",
    "print('%d relevant users'%(len(relevant_users)))\n",
    "tweet_data_original_with_ref_relevant = tweet_data_original_with_ref[tweet_data_original_with_ref.loc[:, 'user'].isin(relevant_users)]\n",
    "print('%d relevant tweets'%(tweet_data_original_with_ref_relevant.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_u = 0.17974, err = 0.42275, t=3.036 (p=3.798E-03)\n"
     ]
    }
   ],
   "source": [
    "# compute differences in CA use\n",
    "from __future__ import division\n",
    "from scipy.stats import ttest_1samp\n",
    "tweet_data_original_with_ref_relevant_reply = tweet_data_original_with_ref_relevant[tweet_data_original_with_ref_relevant.loc[:, 'reply']==1]\n",
    "tweet_data_original_with_ref_relevant_non_reply = tweet_data_original_with_ref_relevant[tweet_data_original_with_ref_relevant.loc[:, 'reply']==0]\n",
    "ca_reply_use = tweet_data_original_with_ref_relevant_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "ca_non_reply_use = tweet_data_original_with_ref_relevant_non_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "ca_use_diff = ca_reply_use - ca_non_reply_use\n",
    "d_u = ca_use_diff.mean()\n",
    "d_u_err = ca_use_diff.std()\n",
    "h_0 = 0.\n",
    "t_stat, p_val = ttest_1samp(ca_use_diff, h_0)\n",
    "print('d_u = %.5f, err = %.5f, t=%.3f (p=%.3E)'%(d_u, d_u_err, t_stat, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 1**:\n",
    "\n",
    "When only considering tweets with a referendum hashtag, slightly more use of Catalan in replies ($d_{u}=0.157, p=0.00380$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weaker condition: use all tweets that contain at least one hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24057 tweets with at least one hashtag\n"
     ]
    }
   ],
   "source": [
    "tweet_data_original_with_hashtag = tweet_data_original[tweet_data_original.loc[:, 'hashtag_count'] > 0]\n",
    "print('%d tweets with at least one hashtag'%(tweet_data_original_with_hashtag.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def run_test(tweet_data):\n",
    "    relevant_users = tweet_data.groupby('user').apply(lambda x: (x.loc[:, 'reply'].min()==0 and\n",
    "                                                                 x.loc[:, 'reply'].max()==1))\n",
    "    relevant_users = relevant_users[relevant_users].index.tolist()\n",
    "    tweet_data_relevant = tweet_data[tweet_data.loc[:, 'user'].isin(relevant_users)]\n",
    "    print('%d relevant users'%(len(relevant_users)))\n",
    "    print('%d relevant tweets'%(tweet_data.shape[0]))\n",
    "    tweet_data_relevant_reply = tweet_data_relevant[tweet_data_relevant.loc[:, 'reply']==1]\n",
    "    tweet_data_relevant_non_reply = tweet_data_relevant[tweet_data_relevant.loc[:, 'reply']==0]\n",
    "    ca_reply_use = tweet_data_relevant_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_non_reply_use = tweet_data_relevant_non_reply.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_use_diff = ca_reply_use - ca_non_reply_use\n",
    "    d_u = ca_use_diff.mean()\n",
    "    N = len(ca_use_diff)\n",
    "    d_u_err = ca_use_diff.std() / N**.5\n",
    "    h_0 = 0.\n",
    "    t_stat, p_val = ttest_1samp(ca_use_diff, h_0)\n",
    "    print('d_u = %.5f, err = %.5f, t=%.3f (p=%.3E)'%(d_u, d_u_err, t_stat, p_val))\n",
    "    return d_u, d_u_err, t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 relevant users\n",
      "24057 relevant tweets\n",
      "d_u = -0.00784, err = 0.01426, t=-0.550 (p=5.825E-01)\n"
     ]
    }
   ],
   "source": [
    "test_results = run_test(tweet_data_original_with_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 2**:\n",
    "\n",
    "Insignificant tendency toward less Catalan in replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last test: consider only tweets that have no hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57401 tweets with no hashtags\n"
     ]
    }
   ],
   "source": [
    "tweet_data_original_no_hashtag = tweet_data_original[tweet_data_original.loc[:, 'hashtag_count'] == 0]\n",
    "print('%d tweets with no hashtags'%(tweet_data_original_no_hashtag.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 relevant users\n",
      "57401 relevant tweets\n",
      "d_u = -0.01135, err = 0.00890, t=-1.275 (p=2.026E-01)\n"
     ]
    }
   ],
   "source": [
    "test_results = run_test(tweet_data_original_no_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 3**:\n",
    "\n",
    "Insignificant tendency toward less Catalan in replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most basic test: @-reply, no hashtag versus no @-reply, hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "def run_compare_test(tweet_data_1, tweet_data_2):\n",
    "    relevant_users = set(tweet_data_1.loc[:, 'user'].unique()) & set(tweet_data_2.loc[:, 'user'].unique())\n",
    "    tweet_data_relevant_1 = tweet_data_1[tweet_data_1.loc[:, 'user'].isin(relevant_users)]\n",
    "    tweet_data_relevant_2 = tweet_data_2[tweet_data_2.loc[:, 'user'].isin(relevant_users)]\n",
    "    print('%d tweets in data 1'%(tweet_data_relevant_1.shape[0]))\n",
    "    print('%d tweets in data 2'%(tweet_data_relevant_2.shape[0]))\n",
    "    print('%d relevant users'%(len(relevant_users)))\n",
    "    ca_1 = tweet_data_relevant_1.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_2 = tweet_data_relevant_2.groupby('user').apply(lambda x: (x.loc[:, 'lang']=='ca').astype(int).sum() / x.shape[0])\n",
    "    ca_use_diff = ca_1 - ca_2\n",
    "    d_u = ca_use_diff.mean()\n",
    "    N = len(ca_use_diff)\n",
    "    d_u_err = ca_use_diff.std() / N**.5\n",
    "    h_0 = 0.\n",
    "    t_stat, p_val = ttest_1samp(ca_use_diff, h_0)\n",
    "    print('d_u = %.5f, err = %.5f, t=%.3f (p=%.3E)'%(d_u, d_u_err, t_stat, p_val))\n",
    "    return d_u, d_u_err, t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_data_1 = tweet_data_original[(tweet_data_original.loc[:, 'reply']==1) & (tweet_data_original.loc[:, 'hashtag_count']==0)]\n",
    "tweet_data_2 = tweet_data_original[(tweet_data_original.loc[:, 'reply']==0) & (tweet_data_original.loc[:, 'hashtag_count']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10370 tweets in data 1\n",
      "13650 tweets in data 2\n",
      "921 relevant users\n",
      "d_u = -0.06189, err = 0.01061, t=-5.830 (p=7.647E-09)\n"
     ]
    }
   ],
   "source": [
    "test_results = run_compare_test(tweet_data_1, tweet_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 4**:\n",
    "\n",
    "Weakly significant effect! **Less** Catalan use in replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain experiment 2: explore non-referendum topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control hashtags\n",
    "\n",
    "What are the most popular control-data hashtags when we take out the referendum-specific hashtags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_hashtags = pd.read_csv('../../data/expanded_fixed_hashtags.csv', index_col=False).loc[:, 'expanded'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starmetre                  1324\n",
      "Venezuela                   806\n",
      "Barcelona                   743\n",
      "España                      581\n",
      "buscandoapacomolina         578\n",
      "Catalunya                   459\n",
      "StarMetre:                  440\n",
      "WorldWide                   440\n",
      "Trends                      439\n",
      "stopLGTB                    403\n",
      "españaesuna                 394\n",
      "LoMásVisto                  375\n",
      "ÚltimaHora                  368\n",
      "Resistencia                 358\n",
      "URGENTE                     352\n",
      "beBee                       348\n",
      "LoMásLeído                  346\n",
      "…                           333\n",
      "Caracas                     331\n",
      "PP                          320\n",
      "SOSVenezuela                309\n",
      "ResistenciaVzla             302\n",
      "LaTorturaNoEsCultura        301\n",
      "HijoPutismo                 298\n",
      "AHORA                       297\n",
      "StarMetre                   292\n",
      "Noticias                    291\n",
      "profesReligión              280\n",
      "stopUE                      273\n",
      "NoTeLoPierdas               273\n",
      "PSOE                        257\n",
      "EstafaBancoPopular          239\n",
      "Política                    237\n",
      "VenezuelaLibre              234\n",
      "Rajoy                       229\n",
      "RecuperemElSeny             217\n",
      "Valencia                    214\n",
      "Parlament                   212\n",
      "Catalonia                   209\n",
      "profesReligion              205\n",
      "FelizDomingo                198\n",
      "AutoDefensas                185\n",
      "TuitUtil                    179\n",
      "LlibertatJordis             176\n",
      "Insurgencia                 174\n",
      "Defiendete                  173\n",
      "Contraataque                170\n",
      "stopglobalizacion           167\n",
      "DefensaPropia               166\n",
      "Rebeldía                    165\n",
      "Disidencia                  165\n",
      "MLB                         160\n",
      "SomosSocialistas            158\n",
      "1O?                         157\n",
      "MarcaEspaña                 157\n",
      "Cataluña                    157\n",
      "DerechoDeRebelión           154\n",
      "Madrid                      152\n",
      "LegítimaDefensa             150\n",
      "Democracia                  149\n",
      "DerechoDeResistencia        149\n",
      "Cs                          148\n",
      "LaInminencia                145\n",
      "FelizLunes                  143\n",
      "Partisano                   142\n",
      "LaOfensiva                  140\n",
      "DerechoDeRevolución         137\n",
      "NoTincPor                   136\n",
      "FelizMartes                 134\n",
      "FelizJueves                 134\n",
      "10Oct                       133\n",
      "GuardiaCivil                131\n",
      "BelenEsteban                131\n",
      "DuiARV                      128\n",
      "PSC                         125\n",
      "ÚLTIMAHORA                  121\n",
      "2Oct                        120\n",
      "1oEstafaAntidemocratica     117\n",
      "1OCT                        117\n",
      "ArdeGalicia                 117\n",
      "EspanaSaleALaCalle          116\n",
      "FelizSabado                 112\n",
      "ACTUALIDAD                  111\n",
      "sosprisiones                110\n",
      "FakeNews                    109\n",
      "EquiparacionYa              108\n",
      "12octFiestaNacional         107\n",
      "DUI                         107\n",
      "CLM                         106\n",
      "stopislam                   106\n",
      "3Oct                        105\n",
      "pactoEducación              105\n",
      "Podemos                     104\n",
      "MiVoto40KatyPerry           103\n",
      "RT                          103\n",
      "MarcaEspaña:                 96\n",
      "CatalanReferendum…           90\n",
      "UP                           88\n",
      "stopsionismo                 86\n",
      "vipdirecto                   86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "pd.set_option('display.max_rows', 100)\n",
    "hashtag_counts = [l.strip().split(' ') for l in codecs.open('../../data/tweets/extra_user_tweets/hashtags_counts.txt')]\n",
    "hashtag_counts = filter(lambda x: len(x)>1, hashtag_counts)\n",
    "hashtag_counts = pd.Series(dict([(h[1], int(h[0])) for h in hashtag_counts])).sort_values(inplace=False, ascending=False)\n",
    "# remove ref hashtags\n",
    "ref_hashtags_intersect = set(ref_hashtags) & set(hashtag_counts.index)\n",
    "hashtag_counts.drop(ref_hashtags_intersect, axis=0, inplace=True)\n",
    "print(hashtag_counts.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why so many Venezuela tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_hashtag = 'Venezuela'\n",
    "tweet_data_with_hashtag = tweet_data_original[tweet_data_original.loc[:, 'hashtags'].apply(lambda x: test_hashtag in x)]\n",
    "print('--------------\\nall data\\n--------------\\n')\n",
    "print('\\n'.join(tweet_data_with_hashtag.loc[:, 'text'].head(50).values.tolist()))\n",
    "print('--------------\\ncontains referendum hashtag\\n--------------\\n')\n",
    "print('\\n'.join(tweet_data_with_hashtag[tweet_data_with_hashtag.loc[:, 'contains_ref_hashtag']==1].loc[:, 'text'].head(50).values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this driven by a small group of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola8400           150\n",
      "jhenderm6          123\n",
      "CanariasMcrc        68\n",
      "mcrc_valladolid     61\n",
      "McrcJaen            60\n",
      "MCRC_Vizcaya        55\n",
      "McrcMurcia          54\n",
      "McrcGuipuzcoa       53\n",
      "mcrc_bcn            51\n",
      "GranadaRC           50\n",
      "Coruna_MCRC         47\n",
      "JapreriaVZ          47\n",
      "BariVenezuela       46\n",
      "betxi_castellon     37\n",
      "IndioMapoyo         29\n",
      "LaRioja_DRC         29\n",
      "grubell_d3v          3\n",
      "mywordsworlds1       3\n",
      "Bank_Practices       2\n",
      "homequevai           2\n",
      "manelmarquez         2\n",
      "ivonnediaz2203       2\n",
      "social_article       2\n",
      "allsetic             2\n",
      "PostreDulce          2\n",
      "adrifadi             1\n",
      "Britovius            1\n",
      "danicorderom         1\n",
      "ThamarManrique       1\n",
      "mostrenco2           1\n",
      "pirataneko           1\n",
      "Municipal_Bank       1\n",
      "mcrc_almeria         1\n",
      "jeff_puente          1\n",
      "PartidoPodrido       1\n",
      "PuesPioPio           1\n",
      "kattolikamente       1\n",
      "libro_lector         1\n",
      "StarMetre            1\n",
      "DonKshu              1\n",
      "IsaTorres78          1\n",
      "socialistahn         1\n",
      "laura_castro3        1\n",
      "SoyCibelino          1\n",
      "Agusti_RM            1\n",
      "manuel_becerrea      1\n",
      "elhilorojo           1\n",
      "jaguimera            1\n",
      "JordiJobatcar        1\n",
      "Lamiabrunetta        1\n",
      "Ataloya              1\n",
      "NavarroMescua        1\n",
      "LlopisMarta95        1\n",
      "OrenseMCRC           1\n",
      "TheObjective_es      1\n",
      "eyeclipse            1\n",
      "bechoch              1\n",
      "bettinagalo          1\n",
      "14manu2013           1\n",
      "JUnodmadrid          1\n",
      "DorisRiveroL         1\n",
      "Marisabeluchi        1\n",
      "IvanGarciaMayer      1\n",
      "RayMcCoyBR           1\n",
      "Name: user, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data_with_hashtag.loc[:, 'user'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
