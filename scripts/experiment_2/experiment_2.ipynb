{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "In which we attempt to implement Experiment 2 from the original study.\n",
    "\n",
    "$H_{0}$: People are equally likely to use Catalan in non-referendum tweets as in referendum-specific tweets.\n",
    "\n",
    "$H_{1}$: People are more likely to use Catalan in non-referendum tweets as in referendum-specific tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id             user  \\\n",
      "0  850626678380535808     CampsCliment   \n",
      "1  850628981040848896         Dom70Bcn   \n",
      "2  850631111747276800  Estrellas_Siete   \n",
      "3  850632361649860608    pasionxespana   \n",
      "4  850632420365873152        MH17files   \n",
      "\n",
      "                                                text  \\\n",
      "0  RT @_Gafas_y_reloj_: El nulo interés de PP y C...   \n",
      "1  RT @MTudela: ‘Té gràcia estudiar a una univers...   \n",
      "2  Las empresas valencianas pueden solicitar #sub...   \n",
      "3  #españaesuna #stopUE #stopOTAN #stopLGTB #stop...   \n",
      "4  RT @pthefigg: @EliotHiggins @benimmo @DFRLab @...   \n",
      "\n",
      "                                          hashtags  contains_ref_hashtag lang  \\\n",
      "0                                              NaN                     0   es   \n",
      "1                                              NaN                     0   ca   \n",
      "2       subvenciones,contratacion,jovenes,Valencia                     0   es   \n",
      "3  espa,stopUE,stopOTAN,stopLGTB,stopglobalizacion                     0   es   \n",
      "4                                      bellingcrap                     0   sw   \n",
      "\n",
      "   lang_conf  retweeted  \n",
      "0   1.000000          1  \n",
      "1   1.000000          1  \n",
      "2   1.000000          0  \n",
      "3   1.000000          0  \n",
      "4   0.428915          1  \n",
      "212476 total tweets\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/tweets/extra_user_tweets/Jan-01-17_Oct-31-17_user_tweets.tsv', sep='\\t', index_col=False)\n",
    "print(data.head())\n",
    "print('%d total tweets'%(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81458 original tweets\n",
      "52364 relevant tweets\n"
     ]
    }
   ],
   "source": [
    "# get rid of retweeted stuff\n",
    "data_original = data[data.loc[:, 'retweeted'] == 0]\n",
    "print('%d original tweets'%(data_original.shape[0]))\n",
    "# language cutoff\n",
    "lang_conf_cutoff = 0.90\n",
    "allowed_langs = set(['es', 'ca'])\n",
    "data_original_high_conf = data_original[(data_original.loc[:, 'lang_conf'] >= lang_conf_cutoff) &\n",
    "                                        (data_original.loc[:, 'lang'].isin(allowed_langs))]\n",
    "print('%d relevant tweets'%(data_original_high_conf.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    52364\n",
      "Name: contains_ref_hashtag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_original_high_conf.loc[:, 'contains_ref_hashtag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 relevant users\n"
     ]
    }
   ],
   "source": [
    "# restrict to users who have tweeted at least once with a referendum hashtag (contains_ref_hashtag==1)\n",
    "# and at least once without a referendum hashtag (contains_ref_hashtag==0)\n",
    "relevant_users = data_original_high_conf.groupby('user').apply(lambda x: (x.loc[:, 'contains_ref_hashtag'].max()==1 and \n",
    "                                                                          x.loc[:, 'contains_ref_hashtag'].min()==0))\n",
    "relevant_users = relevant_users[relevant_users]\n",
    "print('%d relevant users'%(len(relevant_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
